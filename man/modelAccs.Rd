% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Models.R
\name{modelAccs}
\alias{modelAccs}
\title{Generate accuracy statistics for a list of models}
\usage{
modelAccs(models, classNames = NULL)
}
\arguments{
\item{models}{a list of model objects on which to find error statistics}
}
\value{
a list of errors/accuracies: list(confMatrix, userAcc, prodAcc, kappa, VIMP, VIMPoverall)
}
\description{
Given a colleciton of models, this function computes several accuracy and VIMP metrics. See details for a description of each structure returned.
}
\details{
The function returns a list of different accuracy and VIMP datastructures
\describe{
  \item{\sQuote{confMatrix}}{a named list of confusion matrices for each model in the list. Each confusion matrix is a data.frame}
  \item{\sQuote{userAcc}}{a data.frame in which each column represents the user acceracy for a given model. Rows are the accuracies for
     that input class. The final row is the overall user accuracy for that model technique. User accuracy, also called commission error, is the
     the percent of pixels on the map that are what they are predicted to be; that is, the number of correctly identified sites over the number
     that the model predicts to be in that class.}
  \item{\sQuote{prodAcc}}{a data.frame in which each column represents the producer acceracy for a given model. Rows are the accuracies for
     that input class. The final row is the overall producer accuracy for that model technique (the same as for userAcc). Producer accuracy, also called omission error, 
     is the the percent of pixels on the map that are labelled correctly; that is, the number of correctly identified sites over the number
     that the actually are that class.}
  \item{\sQuote{kappa}}{a vector of kappa values for each model type. The kappa-statistic is a measure of how much better this model predicts output
     classes than would be done by chance alone. It is computed as the ratio of the oberved accuracy less that expected by chance, over 1-(chance 
     probabilities). K = (observed accuracy – chance agreement) / (1 – chance agreement). ??? Add the formula as a tex formula... }
  \item{\sQuote{VIMP}}{a named list of variable importance (VIMP) matrices. Each matrix is a data.frame in which columns are different classes
     and rows are input variables used in the model. Entries in the table are the variable importance of an input variable on particular class.}
  \item{\sQuote{VIMPoverall}}{a data.frame showing the overall variable importance (VIMP) for a given model. Columns are different models and entries 
     in the table are the standardized VIMP for an imput variable on that model. Values have been standardized by column so they are (somewhat) comparable
     as the algorithm by which VIMP is computed varies by model--hence the largest value will be 1 in every column. This makes the columns approximately 
     comparable, however, values should be taken with a grain of salt, and perhaps rank order is the most robust comparison.}
}
}

